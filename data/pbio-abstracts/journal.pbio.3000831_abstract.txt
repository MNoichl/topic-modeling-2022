Echolocating bats rely upon spectral interference patterns in echoes to reconstruct fine details of a reflecting objectâ€™s shape. However, the acoustic modulations required to do this are extremely brief, raising questions about how their auditory cortex encodes and processes such rapid and fine spectrotemporal details. Here, we tested the hypothesis that biosonar target shape representation in the primary auditory cortex (A1) is more reliably encoded by changes in spike timing (latency) than spike rates and that latency is sufficiently precise to support a synchronization-based ensemble representation of this critical auditory object feature space. To test this, we measured how the spatiotemporal activation patterns of A1 changed when naturalistic spectral notches were inserted into echo mimic stimuli. Neurons tuned to notch frequencies were predicted to exhibit longer latencies and lower mean firing rates due to lower signal amplitudes at their preferred frequencies, and both were found to occur. Comparative analyses confirmed that significantly more information was recoverable from changes in spike times relative to concurrent changes in spike rates. With this data, we reconstructed spatiotemporal activation maps of A1 and estimated the level of emerging neuronal spike synchrony between cortical neurons tuned to different frequencies. The results support existing computational models, indicating that spectral interference patterns may be efficiently encoded by a cascading tonotopic sequence of neural synchronization patterns within an ensemble of network activity that relates to the physical features of the reflecting object surface.
