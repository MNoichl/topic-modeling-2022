{
  "schema": "https://data.sciveyor.com/schema",
  "version": 5,
  "id": "doi:10.1371/journal.pbio.3000406",
  "doi": "10.1371/journal.pbio.3000406",
  "externalIds": [
    "pii:PBIOLOGY-D-19-00032",
    "pmid:31339883",
    "pmcid:PMC6682158"
  ],
  "license": "This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",
  "licenseUrl": "http://creativecommons.org/licenses/by/4.0/",
  "dataSource": "Public Library of Science",
  "dataSourceUrl": "https://data.sciveyor.com/source/plos",
  "dataSourceVersion": 1,
  "type": "article",
  "title": "Nesting box imager: Contact-free, real-time measurement of activity, surface body temperature, and respiratory rate applied to hibernating mouse models",
  "authors": [
    {
      "name": "Nathaniel E. Kallmyer",
      "first": "Nathaniel E.",
      "last": "Kallmyer",
      "affiliation": "Iowa State University, Ames, Iowa, United States of America"
    },
    {
      "name": "Han Jong Shin",
      "first": "Han Jong",
      "last": "Shin",
      "affiliation": "Iowa State University, Ames, Iowa, United States of America",
      "externalIds": [
        "orcid:http://orcid.org/0000-0002-3423-2825"
      ]
    },
    {
      "name": "Ethan A. Brem",
      "first": "Ethan A.",
      "last": "Brem",
      "affiliation": "University of Texas Southwestern Medical Center, Dallas, Texas, United States of America"
    },
    {
      "name": "William J. Israelsen",
      "first": "William J.",
      "last": "Israelsen",
      "affiliation": "University of Texas Southwestern Medical Center, Dallas, Texas, United States of America",
      "externalIds": [
        "orcid:http://orcid.org/0000-0002-3653-9353"
      ]
    },
    {
      "name": "Nigel F. Reuel",
      "first": "Nigel F.",
      "last": "Reuel",
      "affiliation": "Iowa State University, Ames, Iowa, United States of America",
      "externalIds": [
        "orcid:http://orcid.org/0000-0003-3438-2919"
      ]
    }
  ],
  "journal": "PLOS Biology",
  "date": "2019-07-24",
  "volume": "17",
  "number": "7",
  "pages": "e3000406",
  "tags": [
    "Amniotes",
    "Animal behavior",
    "Animal models",
    "Animal studies",
    "Animals",
    "Behavior",
    "Body temperature",
    "Breathing",
    "Cameras",
    "Data processing",
    "Diodes",
    "Discipline-v3/Amniotes",
    "Discipline-v3/Animal behavior",
    "Discipline-v3/Animal models",
    "Discipline-v3/Animal studies",
    "Discipline-v3/Animals",
    "Discipline-v3/Behavior",
    "Discipline-v3/Biology and life sciences",
    "Discipline-v3/Body temperature",
    "Discipline-v3/Breathing",
    "Discipline-v3/Cameras",
    "Discipline-v3/Computer and information sciences",
    "Discipline-v3/Data processing",
    "Discipline-v3/Diodes",
    "Discipline-v3/Electronics",
    "Discipline-v3/Engineering and technology",
    "Discipline-v3/Equipment",
    "Discipline-v3/Eukaryota",
    "Discipline-v3/Experimental organism systems",
    "Discipline-v3/Hibernation",
    "Discipline-v3/Information technology",
    "Discipline-v3/Light emitting diodes",
    "Discipline-v3/Mammals",
    "Discipline-v3/Medicine and health sciences",
    "Discipline-v3/Model organisms",
    "Discipline-v3/Mouse models",
    "Discipline-v3/Optical equipment",
    "Discipline-v3/Organisms",
    "Discipline-v3/Physiological parameters",
    "Discipline-v3/Physiological processes",
    "Discipline-v3/Physiology",
    "Discipline-v3/Psychology",
    "Discipline-v3/Research and analysis methods",
    "Discipline-v3/Respiration",
    "Discipline-v3/Rodents",
    "Discipline-v3/Social sciences",
    "Discipline-v3/Vertebrates",
    "Discipline-v3/Zoology",
    "Electronics",
    "Equipment",
    "Eukaryota",
    "Experimental organism systems",
    "Hibernation",
    "Information technology",
    "Light emitting diodes",
    "Mammals",
    "Model organisms",
    "Mouse models",
    "Optical equipment",
    "Organisms",
    "Physiological parameters",
    "Physiological processes",
    "Physiology",
    "Psychology",
    "Respiration",
    "Rodents",
    "Type/Community Page",
    "Vertebrates",
    "Zoology"
  ],
  "abstract": "Noncontact methods to measure animal activity and physiology are necessary to monitor undisturbed states such as hibernation. Although some noncontact measurement systems are commercially available, they are often incompatible with realistic habitats, which feature freely moving animals in small, cluttered environments. A growing market of single-board computers, microcontrollers, and inexpensive sensors has made it possible to assemble bespoke integrated sensor systems at significantly lower price points. Herein, we describe a custom-built nesting box imager (NBI) that uses a single-board computer (Raspberry Pi) with a passive infrared (IR) motion sensor, silicon charge-coupled device (CCD), and IR camera CCD to monitor the activity, surface body temperature, and respiratory rate of the meadow jumping mouse during hibernation cycles. The data are logged up to 12 samples per minute and postprocessed using custom Matlab scripts. The entire unit can be built at a price point below US$400, which will be drastically reduced as IR (thermal) arrays are integrated into more consumer electronics and become less expensive.",
  "fullText": "Introduction\n\nMany biological phenomena of interest occur in closed systems that are inconvenient or impossible to measure with traditional wired sensors (e.g., thermocouples, pH probes, pressure sensors). One such environment is the enclosed nest site of a free-moving animal, whether in a laboratory setting or in the field. There is significant biologic interest in monitoring the activity and physiological indicators—such as body temperature and respiration rate—of undisturbed animals with temporal resolution [1], but noncontact options for such measurements during sleep/wake cycles or hibernation have been limited. Historically, the body temperature of small hibernators was measured using thermocouples inserted orally or rectally [2,3], and respiratory rate was determined via timed visual counting of breaths [4]. More recently, surgically implantable or attachable telemeters or loggers have come into common use for measuring conditions such as core body temperature and heart rate in captive and free-ranging animals [5–8].\n\nCurrent methods for monitoring animal activity, respiration, and temperature generally employ commercially available systems designed for rodents in biomedical laboratory settings (summarized in S1 Table). Animal activity–monitoring options typically include infrared (IR) beam-breaking sensors, running wheels, video-based motion tracking, and/or force plate actometers [9–12]. These monitoring systems usually require an uncluttered cage or direct interaction of the animal with the running wheel or force plate and are not amenable to monitoring in enclosed or remote environments. Respiration of small, unrestrained animals is most often measured using a whole-body plethysmograph [13], in which the animal is placed in a dedicated instrument chamber that is not easily integrated into a nest environment. Recent video-based methods for monitoring respiration have required immobilization of the subject [14,15]. Surface body temperature can be determined in a noncontact fashion by thermal imaging or video systems, which require an unobstructed view of the subject [16]. Adoption of such tools has been limited by their size and the proprietary nature of closed systems, which limits convenient data logging or synchronization to other system sensors; moreover, the complete system (sensors, controller, and software) drives up the cost, typically to a quoted purchase in the US$5,000–US$50,000 range. Outside of a laboratory setting, recording of animals in nests or burrows requires direct visual observation by the researcher or the use of visual or IR cameras recording images or videos [17].\n\nRecent advances in single-board computers (e.g., Raspberry Pi), microcontrollers (e.g., Arduino), and inexpensive, high-quality cameras from cell-phone manufacturers have made it possible to create high-precision, custom imagers at a low price point, such as a €100 fluorescent microscope or the US$1 foldscope (US$40 at retail) [18,19]. Some of these low-cost components, such as IR camera modules, have been used to build animal imagers, such as bird box cameras and wildlife imagers. Moreover, there is a greater movement to design “frugal science” instruments to democratize the process of scientific inquiry to all and make everyone a “citizen scientist” [20].\n\nHerein, we demonstrate a new “frugal science” device that, for the first time, integrates three IR camera/detectors and open-source algorithms to provide a nesting box imager (NBI) that monitors animal activity, respiration, and temperature without making contact or disturbing the small animal. At the time of writing, a single unit costs US$400 to build with off-the-shelf parts and would dramatically drop in price at scale. The IR sensors include (1) a passive IR (PIR) motion detector to track levels of activity, (2) a near-IR camera to image the animal and track respiration rate, and 3) a thermal IR camera to track the animal surface temperature. Herein, we detail the design of the open-source NBI and show its utility with a hibernating rodent model, the meadow jumping mouse (Zapus hudsonius). The NBI design presented here overcomes some limitations of existing animal monitoring techniques—namely, improved time and spatial resolution of measurement in the nest. This instrument allows for customized, inexpensive, contact-free measurement of animals in a small environment, with temporal resolution of up to 12 samples per minute over an 8-hour time frame (using a 32 GB flash drive); this recording duration can be dramatically increased by reducing the resolution of the video used to calculate the respiration rate or by collecting this respiration data at less-frequent intervals.\n\nResults\n\nNesting box design for small rodents\n\nThe nesting box was designed after two-chambered nest boxes used for the husbandry of lesser Egyptian jerboas, a much larger but related rodent species [21]. The current boxes were designed to fit inside the cage size used for laboratory housing of meadow jumping mice, with the footprints of the outer atrium and nesting room at 9 × 7 cm and 9 × 12 cm, respectively (Fig 1; design in S1 and S2 Figs). We observed that this design was very effective with this species in that all mice studied chose to sleep inside the dark, back room of the box (nest chamber). The atrium was built with circular entrances to the exterior and nesting room (both 3.2 cm diameter). With the addition of a motion detector, the atrium functioned as a controlled environment to track the periods of high activity of the mouse. An 80-×-60-pixel long-wave IR imager (FLIR Lepton), a 1920-×-1080-pixel, 30-frames-per-second (fps) near-IR camera (Raspberry Pi NoIR camera), and an 890-nm IR illumination source (light-emitting diode [LED] SparkFun) were positioned above the nest chamber. Illumination from the IR LED is outside the visible range of mammals, including rodents [22]. The combination of the IR camera and 890-nm IR illumination thus allowed image capture, regardless of outside illumination, in a manner that did not disturb the subject. The bottom of the nesting box was left open to allow for positioning on top of the natural bedding present in the mouse cage.\n\nThe box lid was hinged to allow for ready access for cleaning. Because of the propensity of rodents to gnaw on objects in their environment, a stainless-steel sheathing (Techflex SSL0.75SV) was installed (Fig 1D) in addition to an enclosed cover (shown complete in Fig 1F) to prevent any access to wires or electronic components. The nest box was constructed of 1-cm-thick high-density polyethylene milled using a desktop computer numerical control (CNC) mill (Shapeoko 3—see Materials and methods below). The full parts list is provided in S2 Table, and a hookup guide is provided in S3 Table and S4 Fig.\n\nMotion measurements for animal activity\n\nThe atrium is monitored by a PIR motion sensor, which detects changes in IR light emitted by a moving mouse. This sensor runs on an independent script (S1 Code) that records the time points of motion events. In this manner, the activity and exit frequency of the mouse can be quantified. To determine the utility of the NBI motion sensor, we compared activity recordings from the NBI to a commercial activity-monitoring system. Simultaneous recordings were obtained from the NBI motion sensor, an under-cage activity-monitoring pad that detects vibrations caused by mouse motion (model number ADX-C, Sable Systems International), and from two PIR sensors mounted inside the cage lid. The ADX-C recordings provide a measure of total animal activity anywhere in the cage, the cage-top PIR sensors capture motion outside of the nest box, and the NBI sensor captures motion inside the nest box atrium. Representative actograms of 48-hour recordings from two mice are shown in Fig 2. Meadow jumping mice are crepuscular/nocturnal, and the activity data show little to no activity outside the nest box during the light cycle. In some cases, the animal appears to have triggered the NBI motion sensor in the atrium but not left the nest box during the day. The actograms plotted from ADX-C vibration data display qualitative agreement with total PIR activity (NBI + cage-top PIR sensors) and with the NBI and cage-top activity data plotted alone. To provide a quantitative comparison of the recording methods, 24-hour periods of activity were integrated over time (S1 Text and S3 Fig) and compared using Pearson’s correlation coefficient (n = 9, 3 periods from 3 animals). The NBI motion data, cage-top motion data, and total PIR motion data are highly correlated with the ADX-C vibration data (S4 and S5 Tables; mean correlations: r = 0.979, r = 0.978, r = 0.983, respectively), suggesting that NBI activity recordings alone could serve as a proxy measure of overall daily activity in this species.\n\nSurface body temperature measurements\n\nSurface body temperature correlates to metabolic state and was an additional desired measure for this hibernating mouse model. A small, inexpensive thermal IR camera (FLIR Lepton) was positioned above the nesting chamber, and the thermal signature of the mouse was tracked to determine temperature over time. These camera units were calibrated to surface temperatures of a thermal cycler block set at different temperature points (Materials and methods) and were validated using a commercial thermistor probe (Fig 3A). For further validation, we used the thermistor probe on proxy models (human hand) and five mice at different temperatures and compared readings from the IR camera (using the linear transfer function found in Fig 3A) to the temperature measured by the thermistor (Table 1 and S2 Data). The average deviation between the two methods was found to be 0.74°C. Spatial temperature maps of the mouse can be generated (Fig 3B); however, in the NBI, the mouse can shift position and partially cover itself with bedding. To overcome these movements and account for large portions of the images containing bedding and other background pixels, only the brightest 10% of the 4,800 pixels were averaged to calculate the camera measurement of mouse surface temperature (“Lepton units”) (Fig 3C). In this manner, the dynamic changes in animal temperatures can be monitored without disturbing the animal, such as the temperature change of a mouse coming out of torpor (Fig 3D).\n\nRespiratory rate measurements\n\nMouse breathing frequency was extracted from video data collected via the near-IR camera (Raspberry Pi NoIR, static images or high-definition [HD] video) (Fig 4A). An algorithm (Materials and methods) was designed to track X- and Y-motion of regions of interest (Fig 4B) to map the periodic motion associated with breathing (Fic 4C). With a moving time window, a Fourier transform was used to convert the time domain data to a frequency domain. The respiratory rate was found as the most prominent peak of this frequency data. The video analysis algorithm was first validated by capturing simulated respiratory frequencies using an elastic proxy mouse and was found to be in agreement in the 30 to 240-breaths-per-minute range (summarized in S3 Text and shown in S5 and S6 Figs). This algorithm was then applied to footage of real mice captured from the NBI. One interesting example is that of a mouse exiting torpor, in which we observed a 2-fold increase in breathing frequency within 10 minutes, which was also validated using the established method of visual inspection of the footage (Fig 4D).\n\nDiscussion\n\nThe desired features of the NBI—namely, contact-free measurement of activity, temperature, and respiration of small animal models in an inexpensive, small form factor for use in the vivarium—were obtained. We found that the meadow jumping mice preferred to sleep in the nest chamber and that the data streams could be conveniently recorded on a flash drive and transferred to a computer for postprocessing after completion of the experiment. Uncompressed video data, produced at approximately 4 GB per hour, limit recordings to a maximum of 8 hours with a standard, 32 GB USB drive. In the current setup, it is powered by a wall plug, so there is no limitation on battery life. A few design elements were included to ensure the robustness of the box against excessive mouse mastication. No electronic components were accessible to the animals, and we never observed any attempts to gnaw on the stainless-steel sheathing enclosing the wires. The top cover for the electronics successfully preserved the equipment and prevented any contact when the animal was active on top of the nest box.\n\nFor activity monitoring, we found the PIR motion sensor in the NBI atrium provided data that correlated with daily animal activity data from a commercial activity-monitoring system. Deployment of the atrium PIR sensor provides an example of how a sensor in an enclosed space can provide a direct measure of a specific activity—in this case, nest box entry/exit and time spent in the atrium. Whereas the reference data from the cage-top motion sensors were recorded using commercial equipment, the modularity of the Python scripts and available Raspberry Pi general-purpose input/output (GPIO) pins allow for addition of additional PIR sensors to the NBI. Such sensors could be used as cage-top sensors or to meet other, specific needs of the research.\n\nBoth the IR and thermal cameras were found to have limitations when obstructed by the nest bedding. Occasionally, the nesting behavior of the mouse covers the camera with nest material; however, by simply lifting the lid and moving it back in place, data can continue to be collected. This could be improved in subsequent designs by selecting less voluminous nesting material and would likely not be a problem when recording species, such as laboratory mice, that build less elaborate nests. We also found that in cold chamber conditions, condensation could build up on the thermal camera lens if care was not taken to remove humid air from the environment. Although some data from thermal cameras affected by condensation still appeared to be valid, we found that, eventually, the camera performance would suffer and require replacement. The temperatures of mice in torpor and active state (23 and 35°C, Fig 3D) also correlate well with data obtained using handheld IR thermometers (S6 Fig), which require disturbing the nest box to make measurements. The IR camera approach also has the added benefit of averaging the temperatures over a larger area versus the point measurements of thermistors, which can vary based on where the probe is positioned for measurement.\n\nRespiratory motion was determined by tracking the position of a visible spot on the fur of the meadow jumping mouse (Fig 4A). This method of motion tracking was found to reliably report movement frequencies between 0.5 and 4 Hz, or 30–240 breaths per minute. At lower frequencies, this algorithm exhibited a positive bias, which could be reduced by widening the windows of time used in Fourier transform analysis (S7 Fig). Although the need for a trackable feature would seemingly limit the ability to monitor different mice, consistent, higher-contrast spots can be artificially created through use of a dye or indelible ink. Reliable tracking requires selection of a region of interest sufficiently large to capture the entire range of motion of a selected feature, a range which may be determined by watching the first 30 seconds of video footage. Although the size of this region depends on the camera angle and distance from the mouse, the user may more intuitively select region bounds by clicking on a reproduced image (via Matlab “ginput” function, S2 Code). A limitation of this algorithm is its susceptibility to additional recognizable features within the selected region of interest that confound image recognition. This interference can be mitigated by using stricter pixel recognition criteria to retain fewer followable shapes. The effects of extraneous features may also be reduced by limiting the region of interest to the range of motion for a single feature, minimizing the chance of additional features appearing. For situations in which movement amplitude is too large to use a small region of interest, a median filter may be applied to frequency data to remove artifact spikes or drops associated with tracking of extraneous features. Although there exist many methods to reduce artifacts, measurements are still limited to periods of relatively stationary behavior during which movement is limited to slight repositioning. Another limitation to this algorithm is that, with a standard computer (&lt;24 GB RAM), the computation time is approximately as long as the analyzed video. This time may be reduced substantially by using lower-resolution video files, which in turn would also allow for longer recording times.\n\nNext steps\n\nThe meadow jumping mouse was a good introductory species to test the NBI, as it required a small, tight design. For larger animal model species, it would be straightforward to expand the design or include multiple cameras to provide additional angles of observation. For field applications, the relatively low power consumption of the NBI would allow long battery-powered runtimes of a weather-proofed version of the design. A quick analysis of part costs reveals that two-thirds of the unit cost is the thermal camera. As these small thermal camera modules are adapted into consumer electronics (as HD cameras were in cell phones), we expect a large price decrease in this more expensive sensor. However, at the current price point of US$400 per NBI without bulk-part savings, this still can be a useful tool in many applications ranging from large-scale animal monitoring in research vivariums to “citizen science” applications at home and primary schools.\n\nMaterials and methods\n\nConstruction of nest box frame\n\nComponents of the nest box frame were prepared by cutting a 9.5-mm (3/8 inch) sheet of white high-density polyethylene with a 3D carbide cutter (ShapeOko 3) into five separate elements. These elements were attached by epoxy glue to form a roofed, floorless, two-room structure (detailed plans in S2 Fig). A circular aperture was cut into the central dividing wall to allow transport between rooms, and an arched gap was cut into the outer wall to allow entry and exit. Four holes were cut into the roof to accommodate electrical components including an IR LED, a thermal camera, a silicon detector camera with no IR filter, and a motion sensor. These electrical components were fastened with adhesive and/or screws.\n\nSensor wiring\n\nSensing and working components of the NBI were controlled by a single-board computer (Raspberry Pi version 3). The thermal camera (FLIR Lepton) was powered with 5 V from the Pi and communicated with the Pi by GPIO pins. A visible spectrum camera enhanced to near-IR light (Pi NoIR version 2) was connected to the Pi by ribbon cable. The mouse was illuminated by an 890-nm IR LED, which was both powered and triggered by a 3-V GPIO pin connected to a 220-Ω resistor, which acted as a voltage divider. A red and green LED were similarly connected to indicate the on/off and data collection state of the vivarium. A PIR motion sensor was powered with 3.3 V from the Pi and also connected to GPIO pins. A shutoff button was also connected to GPIO pins to save video data prior to shut down. A hookup guide is available in S4 Fig and S3 Table.\n\nControl software\n\nThe NBI sensors were controlled by Python scripts (S1 Code). The thermal camera was set to collect an image with 1-second intervals and save each image to a separate text file. The near-IR camera was set to continuously record video data and save this data to an h264 video file after input from the shutdown button. The motion sensor was set to operate continuously and record a time stamp to a text file following an observed motion event. Execution of these sensing functions was automated by a launch script. Libraries and updates installed are listed in S6 Table.\n\nAnimal observations\n\nThis study was conducted according to the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. Animal work described in this manuscript has been approved and conducted under the oversight of the University of Texas Southwestern Institutional Animal Care and Use Committee (protocol #2015–101240) and the Massachusetts Institute of Technology Committee on Animal Care (protocol #0514-048-17). Individual meadow jumping mice were housed singly in polycarbonate cages (46 cm × 24 cm × 15 cm). Each cage was provided with corncob bedding and nesting material (Enviro-dri paper strips), and standard enrichment included a translucent polycarbonate igloo or noninstrumented nest box and a wood block or stick. To allow recording, the standard shelter was replaced with the NBI, and recordings were typically begun following one day of acclimation. Recordings were performed at room temperature (approximately 22°C).\n\nData analysis\n\nData are analyzed with custom Matlab scripts, available in S2 Code. The motion sensor data were recorded as a delimited text file (“motion.txt”), which begins with a header comment noting the experiment start time and then a single-column vector of all time points when the motion sensor is activated. The Matlab script “MouseMove.m” is used to parse this vector and convert the string entries to time values (seconds after experiment start). These can then be plotted, such as the activity diagrams in Fig 2.\n\nThe thermal IR data were recorded as delimited text files of the raw Lepton camera units (60 × 80 matrix) for each time step. These files were then analyzed by the “ThermoVec.m” function to determine the time point from the file name and to take the average pixel value from the top 10% of the pixels. The time points and average pixel values were then saved as a *.csv file for plotting by “plotTherm.m”. This script converts the average pixel value to an actual temperature using the calibration data (Fig 3A) fit with a linear model. The calibration data can be readily obtained for any new camera by first taking images of an object with set surface temperatures (e.g., hot plate, thermal mixer, PCR thermalcycler).\n\nThe IR camera data were processed with a custom Matlab script (“MouseVideoTest.m”) to extract the breathing rates over time. In brief, the green pixel data (highest contrast of the RGB camera data) were converted to a binary image (Fig 4B) based on user-selected pixel intensity threshold, and a shape recognition algorithm (centroid function Matlab) was used to track regions of interest on the mouse (Fig 4C). A Fourier transform was applied to a moving timeframe, and the respiratory rate was determined as the most prominent frequency peak in the transformed data. Detailed analysis instructions are provided in S3 Text.\n\nEthics statement\n\nThis study was conducted according to the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. Animal work described in this manuscript has been approved and conducted under the oversight of the University of Texas Southwestern Institutional Animal Care and Use Committee (protocol #2015–101240) and the Massachusetts Institute of Technology Committee on Animal Care (protocol #0514-048-17).\n\nSupporting information"
}