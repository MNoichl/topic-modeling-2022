{
  "schema": "https://data.sciveyor.com/schema",
  "version": 5,
  "id": "doi:10.1371/journal.pbio.0000050",
  "doi": "10.1371/journal.pbio.0000050",
  "license": "This is an open-access article distributed under the terms of the Public Library of Science Open-Access License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.",
  "licenseUrl": "https://creativecommons.org/licenses/by/4.0/",
  "dataSource": "Public Library of Science",
  "dataSourceUrl": "https://data.sciveyor.com/source/plos",
  "dataSourceVersion": 1,
  "type": "article",
  "title": "Current Approaches to the Study of Movement Control",
  "authors": [
    {
      "name": "Alla Katsnelson",
      "first": "Alla",
      "last": "Katsnelson",
      "affiliation": "alla_k@ureach.com <alla_k@ureach.com>"
    }
  ],
  "journal": "PLoS Biology",
  "date": "2003-11",
  "dateElectronic": "2003-11-17",
  "volume": "1",
  "number": "2",
  "pages": "e50",
  "tags": [
    "Discipline/Biotechnology/Bioengineering",
    "Discipline/Neuroscience",
    "System Taxonomy/Homo (human)",
    "System Taxonomy/Primates",
    "Type/Primer"
  ],
  "abstract": "A combination of neural recording, behavioural experiments and computational modeling is needed to understand the control of movement.",
  "fullText": "Almost every sensation we experience or decision we make results in movement. Actions like reaching for a glass of water, shifting a car's transmission from first to second gear, or petting a dog are generally accomplished without much difficulty or reflection. But in order to pet that dog, the brain must take into account an enormous array of information, including the starting position and velocity of the arm, the force required in the fingers to stroke rather than annoy, and the dog's position in space, in order to signal the stimulation of muscle and angling of joints for the necessary movement.\n\nThe brain must therefore integrate sensory information from several sources—vision, touch, and even the internal sensors on muscles and joints—to generate an appropriate movement. To understand how these elements of motor cognition interact to produce coherent motor behaviour, research is conducted at several levels. Psychophysical studies of simple movement tasks define the range of possible motor behaviours and adaptations (Figure 1). Electrophysiological recordings from neurons in the sensorimotor system can resolve signals present in the brain during particular motor behaviours. And more recently, computational models are being used to simulate simple movement tasks and compare the outcomes with real behaviours and real neural elements, thereby testing ideas of how brain signals are processed to achieve sophisticated motor control.\n\nOne mechanism responsible for controlling numerous biological processes is feedback. Broadly speaking, feedback mechanisms use the outcome of a biological process to continually adjust and fine-tune that process, whether it be gene transcription through operons, hormone production within the body, or the act of reaching for a target. While feedback mechanisms are certainly a factor of motor control—sensory feedback, for example, allows you to judge whether you have stroked your dog—feedback cannot be the primary biological mechanism for control of an ongoing movement, simply because it takes too long. The time delay for visual feedback on an arm movement is estimated to be 150–250 ms, but the brain has the capability to execute movements within as little as 150 ms (Kawato 1999).\n\nInstead, researchers have proposed the existence of internal models as a key mechanism for regulating motor control. Simply put, an internal model is a learned script in the central nervous system that takes into account the dynamical properties of the body to predict the consequences of a motor command (Davidson and Wolpert 2003). From the fact that one brain commands the body through a lifetime of massive changes in size and density, it is immediately obvious that the basis for predictions engendered by internal models must be constantly modified with experience. Distinct internal models are thought to act as predictors for distinct parameters of a motor act—for example, one internal model might represent hand velocity and another might represent position in space. In this sense, internal models have been referred to as “motor primitives” or “building blocks” (Wolpert et al. 2001) that might interact to generate specific coordinated movements.\n\nInternal models themselves are of two types (Figure 2). Forward internal models predict sensory consequences of a planned motor event, and inverse internal models calculate how a movement should be controlled to achieve the desired consequence to essentially transform the desired movement into a motor command based on this calculation. In a review synthesizing a full-scale concept of how multiple internal models might interact with each other, Wolpert et al. (1998) described a complex modularity between different parameters and a computational mechanism that could account for the dynamic interaction between the different modules.\n\n      Behavioural Relevance of Internal Models\n      \nWhile internal models for motor planning were initially conceived as theoretical constructs to deconstruct the cognitive processes' underlying movement, psychophysics-based research conducted over the last decade has made much progress in substantiating the existence of internal models in human subjects as well as nonhuman primates and also in defining how these models function for different parameters of a movement task. In a well-designed psychophysical study, hypothetical neurophysiological processes are tested by evaluating subjects' responses to experimentally controlled stimuli and comparing the results to theoretical predictions. Advances in robotics have refined the ability to control the experimental environment.\n\nIn an early experiment on the existence of internal models, subjects were asked to perform reaching movements while holding a robotic handle that could exert unexpected forces during the movement. They at first made errors in the task, but with practice learned the correct movement trajectories that took the learned forces into account. When the forces were no longer applied, subjects again made errors, the trajectories of which were mirror images of the errors initially produced when the forces were first applied (Shadmehr and Mussa-Ivaldi 1994). The symmetry of these errors, as well as the observation that subjects were consistently able to generalize training experience to movement outside the area in which they were trained, suggested that subjects generated an internal model of hand trajectory to deal with the applied forces and that with experience this model became more refined for the task.\n\nExperiments such as this one, which examine how broadly learning of specific motor tasks is generalized outside the training conditions, provide a key paradigm for investigating the functional organization of internal models. Generalization experiments are designed to tease out different components of a motor task (e.g., arm velocity and direction) and involve analysis of the systematic errors made when new forces are imposed on trained tasks.\n\nKawato (1999) explains that theoretically, if generalization is perfect, then a subject who has learned a motor task under specific conditions (e.g., a force field) can go on to perform it perfectly in a different context (e.g., without the force field), adapting the parameters (e.g., velocity) appropriately without any further training. Such a model would be something of a monster, because it would have to be able to simultaneously analyze all of the contributions to a motor task. On the other hand, if motor learning is not generalized at all beyond the trained task, then any changes in context would bring subjects back to square-one error levels. This scenario would be reflective of an internal model that was essentially a look-up table, requiring rote memorization of specific conditions related to specific outcomes. Instead of either of these extremes, studies have consistently shown an intermediate degree of generalization, with changes in context disrupting the task but not setting performance to zero (see Imamizu et al. 1995; Conditt et al. 1997; Kawato 1999). This imperfect generalization supports a modularly organized structure of internal models, like that proposed by Wolpert et al. (1998), described above.\n\nTo date, internal models encoding several distinct parameters of motor control in the arm have been hypothesized based on generalization experiments. A few examples include hand velocity (described above; Thoroughman and Shadmehr 2000), inertial anisotropy (the relationship between hand acceleration and arm inertia; Flanagan and Lolley 2001), and load force (a measure of the relationship between movement and hand grip; Flanagan and Wing 1997). Importantly, generalization experiments can also reveal that parameters, such as timing information, are not represented as internal models (Conditt and Mussa-Ivaldi 1999).\n\nAn elegant experiment conducted in space on the Neurolab space shuttle mission suggested the existence of an internal model relating to gravity by examining the timing of a simple catching task (McIntyre et al. 2001). During space flight (at zero gravity) as well as before and after (at normal Earth gravity), experimenters measured limb stiffness and muscle activation in the bicep (two components of catching) while astronauts caught a ball dropped from above at different initial speeds. Although the astronauts could see that the ball was not accelerating as it would on Earth, subjects tended to start catching movements too early in zero gravity, reflecting a partial generalization of the effects of gravity.\n\nIn this month's issue of PLoS Biology, Hwang et al. (2003) address an apparent contradiction among results of motor-learning experiments. Internal models of both acceleration and velocity show broad generalization in space. This would imply that we do not form an internal model of position. However, the finding that human subjects can readily adapt to position-dependent force fields shows that position must be encoded. To resolve this issue, the authors examined adaptation to forces that were dependent on both position and velocity of the limb. The results suggest that both position and velocity are encoded in a multiplicative fashion (via a gain field). The most parsimonious way to view this finding is that neural elements actually encode a direction signal that is modulated by position; such a conclusion is strongly supported by the results of neural recording experiments in motor cortex.\n\n      Practical Implications\n      \nUnderstanding the control of movement is not just an abstract exercise. As another paper in this month's issue of PLoS Biology shows, signals extracted from the brain can be used directly to control artificial prosthetic devices, which in principle could be adapted to help people with permanent paralysis interact with their environment. Carmena et al. (2003) recorded multiple signals from the cortex of monkeys trained to perform reaching and grasping tasks. These signals, in turn, were used to control a robotic arm to perform the same tasks, and soon the animals were able to directly control the artificial device apparently by simply thinking about the movement. The investigators recorded signals from many brain areas and used several types of empirically derived procedures to extract the necessary signals from the neural-recording data. They demonstrated that multiple cortical areas contain information about hand position, velocity, and other relevant signals, albeit to different degrees. They further showed data suggesting that the brain may adapt to incorporate an internal model of the artificial manipulandum. As more research fills in the gaps in our understanding of the cortical control of movement, it is possible that even more sophisticated control of such artificial devices could be practically achieved.\n\n      Conclusions\n      \nA major goal in cognitive research, of course, is to directly demonstrate hypothesized mechanisms of cognitive processes in the cellular structure and organization of the brain. Internal models are powerful concepts for understanding how the nervous system breaks down motor tasks. Psychophysical experiments such as those described above can provide a theoretical framework from which to approach neurophysiological investigation, but comparisons of neuronal firing properties, both in the cerebellum and the cortex, with mathematical properties of computational models can bring these models closer to a physiological reality.",
  "externalIds": [
    "pmid:14624251",
    "pmcid:PMC261888"
  ]
}