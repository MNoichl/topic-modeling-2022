{
  "schema": "https://data.sciveyor.com/schema",
  "version": 5,
  "id": "doi:10.1371/journal.pbio.3000882",
  "doi": "10.1371/journal.pbio.3000882",
  "externalIds": [
    "pii:PBIOLOGY-D-20-00556",
    "pmid:33141817",
    "pmcid:PMC7665803"
  ],
  "license": "This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",
  "licenseUrl": "http://creativecommons.org/licenses/by/4.0/",
  "dataSource": "Public Library of Science",
  "dataSourceUrl": "https://data.sciveyor.com/source/plos",
  "dataSourceVersion": 1,
  "type": "article",
  "title": "Independent representations of self-motion and object location in barrel cortex output",
  "authors": [
    {
      "name": "Jonathan Andrew Cheung",
      "first": "Jonathan Andrew",
      "last": "Cheung",
      "affiliation": "Department of Biological Sciences, Section of Neurobiology, University of Southern California, Los Angeles, California, United States of America; Neuroscience Graduate Program, University of Southern California, Los Angeles, California, United States of America",
      "externalIds": [
        "orcid:https://orcid.org/0000-0002-4379-8601"
      ]
    },
    {
      "name": "Phillip Maire",
      "first": "Phillip",
      "last": "Maire",
      "affiliation": "Department of Biological Sciences, Section of Neurobiology, University of Southern California, Los Angeles, California, United States of America; Neuroscience Graduate Program, University of Southern California, Los Angeles, California, United States of America"
    },
    {
      "name": "Jinho Kim",
      "first": "Jinho",
      "last": "Kim",
      "affiliation": "Department of Biological Sciences, Section of Neurobiology, University of Southern California, Los Angeles, California, United States of America"
    },
    {
      "name": "Kiana Lee",
      "first": "Kiana",
      "last": "Lee",
      "affiliation": "Department of Biological Sciences, Section of Neurobiology, University of Southern California, Los Angeles, California, United States of America"
    },
    {
      "name": "Garrett Flynn",
      "first": "Garrett",
      "last": "Flynn",
      "affiliation": "Department of Biological Sciences, Section of Neurobiology, University of Southern California, Los Angeles, California, United States of America",
      "externalIds": [
        "orcid:https://orcid.org/0000-0002-7996-8713"
      ]
    },
    {
      "name": "Samuel Andrew Hires",
      "first": "Samuel Andrew",
      "last": "Hires",
      "affiliation": "Department of Biological Sciences, Section of Neurobiology, University of Southern California, Los Angeles, California, United States of America",
      "externalIds": [
        "orcid:https://orcid.org/0000-0003-3498-0388"
      ]
    }
  ],
  "journal": "PLOS Biology",
  "date": "2020-11-03",
  "dateAccepted": "2020-09-18",
  "dateReceived": "2020-03-03",
  "volume": "18",
  "number": "11",
  "pages": "e3000882",
  "tags": [
    "Action potentials",
    "Agriculture",
    "Anatomy",
    "Animal anatomy",
    "Animal cells",
    "Animal management",
    "Animal performance",
    "Animal physiology",
    "Cell biology",
    "Cellular neuroscience",
    "Cellular types",
    "Cognitive psychology",
    "Cognitive science",
    "Discipline-v3/Action potentials",
    "Discipline-v3/Agriculture",
    "Discipline-v3/Anatomy",
    "Discipline-v3/Animal anatomy",
    "Discipline-v3/Animal cells",
    "Discipline-v3/Animal management",
    "Discipline-v3/Animal performance",
    "Discipline-v3/Animal physiology",
    "Discipline-v3/Biology and life sciences",
    "Discipline-v3/Cell biology",
    "Discipline-v3/Cellular neuroscience",
    "Discipline-v3/Cellular types",
    "Discipline-v3/Cognitive psychology",
    "Discipline-v3/Cognitive science",
    "Discipline-v3/Electrophysiology",
    "Discipline-v3/Medicine and health sciences",
    "Discipline-v3/Membrane potential",
    "Discipline-v3/Neuronal tuning",
    "Discipline-v3/Neurons",
    "Discipline-v3/Neurophysiology",
    "Discipline-v3/Neuroscience",
    "Discipline-v3/Perception",
    "Discipline-v3/Physiology",
    "Discipline-v3/Psychology",
    "Discipline-v3/Sensory perception",
    "Discipline-v3/Social sciences",
    "Discipline-v3/Touch",
    "Discipline-v3/Vibrissae",
    "Discipline-v3/Zoology",
    "Electrophysiology",
    "Membrane potential",
    "Neuronal tuning",
    "Neurons",
    "Neurophysiology",
    "Neuroscience",
    "Perception",
    "Physiology",
    "Psychology",
    "Sensory perception",
    "Touch",
    "Type/Research Article",
    "Vibrissae",
    "Zoology"
  ],
  "abstract": "During active tactile exploration, the dynamic patterns of touch are transduced to electrical signals and transformed by the brain into a mental representation of the object under investigation. This transformation from sensation to perception is thought to be a major function of the mammalian cortex. In primary somatosensory cortex (S1) of mice, layer 5 (L5) pyramidal neurons are major outputs to downstream areas that influence perception, decision-making, and motor control. We investigated self-motion and touch representations in L5 of S1 with juxtacellular loose-seal patch recordings of optogenetically identified excitatory neurons. We found that during rhythmic whisker movement, 54 of 115 active neurons (47%) represented self-motion. This population was significantly more modulated by whisker angle than by phase. Upon active touch, a distinct pattern of activity was evoked across L5, which represented the whisker angle at the time of touch. Object location was decodable with submillimeter precision from the touch-evoked spike counts of a randomly sampled handful of these neurons. These representations of whisker angle during self-motion and touch were independent, both in the selection of which neurons were active and in the angle-tuning preference of coactive neurons. Thus, the output of S1 transiently shifts from a representation of self-motion to an independent representation of explored object location during active touch.",
  "fullText": "Introduction\n\nA major function of the mammalian cortex is to integrate sensory input with self-knowledge to form mental representations of the external world to guide flexible behavior [1,2]. Object location is one such representation, and it is essential for skillful navigation and object interaction [3–5]. Object locations can be rapidly and accurately identified via active touch [6–10]. In active touch, mechanosensory input is thought to be referenced to the movement and position of tactile sensors to produce a mental percept not of the self but of the object under investigation [2]. Determining where and how these sensory and motor signals are transformed by neural circuits into a representation of the external world would improve our understanding of brain function.\n\nHead-fixed mice are an excellent model system to investigate the neural basis of object localization. They can locate objects along the anteroposterior axis of the face with submillimeter precision by sweeping a single whisker back and forth (i.e., whisking; [10]) and interpreting the mechanically evoked neural activity patterns transduced in the follicle that holds the whisker [11–13]. Similar sensorimotor mechanisms may underlie texture discrimination in rodents [14–16] and tactile sensing with tools in humans [17–18]. High-speed whisker imaging and mechanical models of whisker deformation provide rich knowledge of the sensory input and motor program underlying the computation of object location [19–24]. Early cortical processing of tactile input is topographically organized into columns of primary somatosensory cortex (S1) that have a one-to-one correspondence with large facial whiskers [25]. Intrinsic signal imaging allows whisker-specific neural activity to be targeted for electrical recording [26–27]. Furthermore, transgenic mouse lines allow assignment of observed neural activity patterns to neurons of specific types [28–29]. Thus, mice allow a dissection of self-motion and object-location representation at behavioral, perceptual, computational, and neural circuit levels.\n\nA prime candidate for the construction of neural representations of object location are layer 5 (L5) pyramidal neurons of S1. S1 activity is required for whisker-based anteroposterior object localization [27] (though not object detection; [30]). L5 pyramids contain the major output of S1 to cortical and subcortical targets involved in decision-making, action selection, and motor control [29, 31–33]. Distinct cellular compartments of L5 pyramids receive sensorimotor features that are assembled in models of object-location representation and perception [10,34]. These features include sensory representations of self-motion from ventral posteromedial nucleus of the thalamus (VPM) [35–36] of touch from VPM and layer 3 (L3) and layer 4 (L4) of S1 [37–39] and efference copy from primary motor cortex (M1) [40–41]. Object location–specific calcium responses have been observed in tuft dendrites [42], apical trunk, and soma [43] of L5 pyramids. Thus, L5 pyramidal neurons have the appropriate inputs and outputs to transform sensation into an object-location representation that guides flexible behavior.\n\nHere, we use single-unit juxtacellular electrophysiology to investigate the neural representation of sensory input, self-motion, and object location in L5 excitatory neurons during behavior. Over half of the active neurons encode self-motion during free-whisking, and a third encode the location of touched objects. This encoding does not require specialized training. Population responses to touch can decode object location with submillimeter accuracy. Contrary to expectations, the cellular identity and positional preferences of the touch-evoked object-location representation were uncorrelated with the self-motion representation during free-whisking. Thus, touch activates an independent representation of object location in L5, rather than amplifying an underlying representation of self-motion. These data suggest that a perceptual transformation from self to sensed object is accomplished by neural circuits interacting with L5 pyramidal neurons of S1.\n\nResults\n\nExperimental design\n\nTo investigate the organization of neural representations in L5 during whisker-mediated exploration, we used variations of a go/no-go whisker-guided object-localization task in head-fixed mice [27]. Water-restricted mice (n = 16 VGAT-ChR2-EYFP mice) were trained to whisk and contact a smooth vertical pole presented randomly across a contiguous range (10 mm) of pole positions along the anteroposterior axis about 8 mm lateral from the whisker pad (Fig 1A). Mice were trimmed to a single whisker (C2) across all training and recording sessions. Whisker motion and object interactions were tracked from an overhead view at 1,000 frames per second (fps) (Fig 1B). Whisker traces were converted to time series of whisker azimuthal angle (i.e., angle), the Hilbert decomposition of amplitude, midpoint, and phase [41] and touch (Fig 1C). We serially recorded optogenetically tagged single neurons via blind juxtacellular loose-seal patch in and around layer 5B (L5B) of the C2 whisker representation of S1 (Fig 1D, S1A and S1B Fig; see Materials and methods). Each trial consisted of a 0.5-s pre-pole period, followed by a 0.75-s stimulus sampling period, and then a 1.25-s answer period in which licks triggered water dispensing or a brief time-out (Fig 1E). We recorded from 149 single units during active touch behavior. Twenty units were silent and 14 others were putative inhibitory neurons, based on short latency spiking in response to illumination of S1 with 473-nm light (S1C–S1E Fig), leaving 115 active putative excitatory neurons. Putative inhibitory units predominantly had shorter spike durations and more symmetric peak-to-trough heights (S1D–S1F Fig). To quantify the neural representation of sensorimotor features, we correlated these features to the times of detected action potentials.\n\nRepresentation of self-motion\n\nWe first examined the neural representation of self-motion during free-whisking (S2A Fig). Most neurons (87 of 115 active units) were significantly (chi-squared test) modulated (positively or negatively) by whisking, with the mean firing rate significantly increased from 4.7 ± 5.4 spikes per second (spks/s) (mean ± SD) during nonwhisking to 5.3 ± 6.7 spks/s (mean ± SD) during whisking (Fig 2A). The bulk of this increase occurred among neurons with nonwhisking firing rates in excess of 5 spks/s. Whisking-tuned neurons were relatively uniformly distributed across the recorded depth (S2B Fig). Since whisking was volitional [10], we could not dictate the exploration time or range of the mouse (S2C and S2D Fig), but many neurons (54/115) were significantly modulated with respect to whisker angle within the chosen range of whisking (Fig 2B and 2C). Across the population, preferred angles spanned the range of whisking (Figs 2C and S2E). Most of these neurons (43/54) were also modulated by phase in the whisker cycle (Figs 2B, 2D and S2F) with representations tiling the phase space. Across the population of 115 active putative excitatory units, 43 were tuned to whisker phase and angle, 11 to angle only, 0 to phase only, and 61 to neither (Fig 2E). Among neurons tuned to at least one, the mean depth of modulation to angle was significantly greater than to phase (p = 5.0e-5, Fig 2F and 2G, see Materials and methods). Greater modulation to angle was more correlated with greater modulation to whisking midpoint than to amplitude, phase, or velocity (Fig 2H and 2I). The absolute modulation depth of midpoint was most similar to that of angle (Fig 2J). This suggests that midpoint-correlated inputs are important for constructing an angle-tuned representation, which is consistent with the importance of midpoint in predicting choice during object localization [10]. These data show that during free-whisking, L5 excitatory neurons encode a representation of self-motion that is more specific to whisker angle than phase of whisk cycle.\n\nRepresentation of object location\n\nWe then examined sensorimotor representations in the same neurons during active touch. Of the active putative excitatory neurons, 50 out of 115 were excited by touch. Touch responses were temporally sharp with short latency (Table 1, S3A Fig). In 39 of the 50 touch neurons, the number of spikes evoked was dependent on the anteroposterior position of the pole (Fig 3A). These touch location–tuned neurons were concentrated between 690 and 890 μm from pia (Fig 3B), roughly corresponding to L5B (Fig 1D, [44]). Touch-location tuning was driven by a greater probability of spiking and a greater number of spikes evoked per touch (S3B–S3D Fig). Touch location and maximum (max) curvature change were weakly correlated (mean Pearson’s r = 0.16 ± 0.13 SD, n = 115 sessions). To dissociate the potential effects of touch force from object-location tuning, we stratified angle-tuning curves into high and low max curvature halves in each angle bin. Stronger touches were associated with higher evoked firing rates than weaker touches (increase of 18.6% ± 2.2% SEM; p = 2.1e-4, t-stat 4.0, df = 49, one-sample t test), but object-location tuning was independent of touch strength (S3F–S3L Fig). Across the tuned population, the preferred object location spanned the entire range of touched pole locations (Fig 3C and 3D). The mean half-max width response was 1.8 mm (approximately 9.2° of azimuth) (Fig 3E). Thus, this subpopulation of L5 excitatory neurons form a distributed neural code for touched-object location.\n\nTouch-location tuning did not require training in whisker-guided location discrimination. We performed recordings in two related tasks. In 85 naïve recording sessions with untrained mice (n = 10), water rewards were given randomly on 50% of the trials, regardless of pole location, whereas in 30 trained sessions, trained mice (n = 6) were first trained to discriminate go and no-go locations as in the study by Cheung and colleagues, 2019 [10] (Fig 4A and 4B), with water only available in the posterior go range. Trained mice made significantly more touches with less time spent whisking than naïve mice (S4A Fig). However, there was no significant difference in the proportion of touch-responsive units that were tuned to object location between naïve (n = 24/31, 77.4%) and trained (n = 15/19, 78.9%) (p = 0.27, Fisher’s exact test; Fig 4C), though we did observe a larger proportion of touch-responsive units in trained animals (S4B Fig). The width of the tuning was indistinguishable between the groups (Fig 4D), and the preferred locations spanned the full range of presented locations in both naïve and trained mice (Fig 4E and 4F).\n\nTo access location information from a distributed representation, downstream neurons must sample multiple members of the representing population. However, the number of possible inputs to a neuron is limited. Thus, we wondered how accurately the object location could be determined from varying numbers of randomly sampled object-location tuned neurons. We constructed a multinomial generalized linear model (GLM) to predict the location of the pole from the distribution of the number of spikes evoked by single touches (see Materials and methods, S3E Fig). A linear classifier pooling the touch-evoked spike counts from 25 of our location-tuned neurons (the subset with ≥75 touches in ≥80% of binned pole locations) predicted the pole location to ≤0.5-mm distance from actual on 60.5% ± 1.3% (mean ± SD) of touches (Fig 5A and 5B).\n\nOur prior work showed that expert mice discriminate location to ≤0.5-mm resolution in this task [10]. How many location-tuned neurons are required to meet or exceed the psychometric performance of these expert mice? We constructed neurometric performance curves from the predicted object locations and compared them to mean psychometric curves from Cheung and colleagues, 2019 [10] (Fig 5C). Random sampling from five or more location-tuned neurons produced model performance that met or exceeded expert behavior (Fig 5D, see Materials and methods). This suggests that downstream neurons that sample from at least five location-tuned L5B neurons have access to a touch-by-touch object-location representation that meets or exceeds the behavioral performance of the mouse.\n\nActive touch evokes an object-location representation that is independent of self-motion tuning\n\nDoes touch amplify an underlying whisker-angle representation during free-whisking? Or does touch evoke an object-location representation that is independent of the free-whisking representation? Multiple lines of evidence support the independent model. First, 47% of neurons were tuned to angle during free-whisking, and 36% were tuned to angle during touch, but only 19% neurons were tuned to angle under both conditions (Fig 6A). Thus, tuning during free-whisking is neither necessary nor sufficient to exhibit angle tuning during touch. Moreover, this co-tuned overlap is nearly identical to an expected overlap (17%) if the two representations were independently distributed across the population.\n\nWe compared angle-tuned responses between free-whisking and touch in individual neurons using spike integration windows derived from each neuron’s touch-evoked response (Figs 6B and S5A). Whisker angle at touch is tightly correlated with (S5B Fig) and a proxy for the object location in this analysis (Fig 3, see Materials and methods). The average absolute modulation depth was 3.7× greater for touch (14.2 ± 1.7 Hz; mean ± SEM) than for whisking (3.8 ± 0.5 Hz; mean ± SEM) (Fig 6C). Note that since touch-evoked responses tended to be much larger, many neurons with higher absolute modulation to touch than whisking were not significantly touch-angle tuned (p &lt; 0.01 analysis of variance [ANOVA] across angle bins). The shapes of normalized angle-tuning curves in each neuron were uncorrelated between the two conditions and not significantly different from a randomly shuffled population (Fig 6D). Finally, in co-tuned units, the angles of max response during free-whisking and at touch were significantly different (mean ± SD = 13.1° ± 11.1°, p = 1.7e-5, one-sample t test) and weakly correlated (Pearson’s r = 0.23) (Fig 6E). Repeating these analyses using phase instead of angle as the independent variable showed similar results (S6 Fig). We conclude that rather than amplifying an underlying tuning to whisker angle during free-whisking, active touch shifts population activity from a representation of self-motion to an independent representation of object location.\n\nDiscussion\n\nWe quantified sensorimotor representations in L5 excitatory neurons during active whisker exploration and touch using juxtacellular electrophysiology (Fig 1). Most active neurons represented self-motion during free-whisking (Fig 2), with greater modulation by whisker angle than whisker phase. A third of L5 excitatory neurons were highly modulated by touched-object location (Fig 3). This location tuning did not require training (Fig 4). Pooling activity of five random location-tuned units discriminated object location with equal or better skill than expert mice (Fig 5), suggesting that neurons in downstream areas need only sample a handful of S1 outputs to access behaviorally relevant representations of object location. The representations of whisker angle and phase during free-whisking and at touch were uncorrelated at population and within-cell levels (Figs 6 and S6). Together, these data indicate that active touch shifts S1 output from a sensory representation of self-motion to a perceptual representation of object location.\n\nLimitations and advantages of the research\n\nWe note several limitations of our work. We primarily targeted recordings to L5B [44], where thick-tufted pyramidal neurons are more prevalent, using axial penetration distance from pia to estimate cell depth. However, cell types do not strictly respect layer boundaries, and this depth estimate is only accurate to within ±30 μm [45]. Because we recorded across multiple days during behavior, we did not attempt to recover cell morphology by juxtacellular filling. Thus, we could not differentiate cell types (e.g., thin- versus thick-tufted L5 pyramids, or L6A corticocortical cells [46]), their projection patterns (e.g., intertelencephalic [IT] versus pyramidal tract [PT]), or the extent to which whisker motion and object location tuning are segregated between these two classes as hypothesized in rat [47]. Half of object location–tuned units were also tuned to whisker angle during free-whisking, suggesting that these two features may not be cleanly divided between IT and PT cell types. Use of projection-specific L5 cre-lines (e.g., IT versus PT; [29]) could determine the extent to which self-motion and object-location representations are segregated by cell type and projection class in future work. Finally, we did not establish a causal role for location coding neurons in driving perceptual choice during object localization. Recent developments in structured illumination and optogenetics [48–49] may allow testing this in the future.\n\nHowever, our approach also had several advantages over prior investigations of S1 activity during active whisker touch. Optogenetic tagging allowed us to identify putative excitatory versus inhibitory units. Juxtacellular loose-seal recording, considered a gold standard for extracellular single-unit isolation [50], allowed us to sample activity with high accuracy and temporal fidelity without bias from firing rate, avoid potential misassignment of synchronous touch-evoked spikes [39], and avoid false negative responses common in calcium imaging when scanning population-sized fields of view [51]. The high temporal resolution of electrophysiology allowed us to determine whisker angle and phase tuning during free-whisking (Fig 2) and its relationship to tuning at touch (Figs 3 and 6), which was not investigated in prior studies using calcium imaging [42–43].\n\nThe transformation from self-motion to object-location representation\n\nContrary to our expectations, we found that within L5, the cellular identity of angle-tuned neurons (Fig 6A and 6C) and their angle preferences (Fig 6B and 6E) were uncorrelated between free-whisking and at touch. The same was true for phase tuning (S6 Fig). This was surprising, because prior stereotrode recordings across layers of rat S1 showed touch responses that were highly amplified when they occurred at the peak of free-whisking phase tuning [52]. Moreover, the preferred phase during free-whisking and at touch were tightly correlated. The reason for our differing results is unclear. Our mice were head-fixed, whereas rats could crane their head, which could introduce head-direction effects on neural coding. There could be species-specific differences in phase, position, or touch encoding. Potentially supporting this notion, a recent report found no relationship between phase preference of stick-slip response and of surface or air whisking in mouse S1 [53]. A more tantalizing possibility is that the encoding of touch responses with respect to whisking features changes across the layers of S1. We targeted recordings to excitatory neurons of infragranular output layers, whereas Curtis and Kleinfeld's touch neurons were mostly found in granular input and deep infragranular layers. Phase tuning from reafferent input is prevalent in granular L4 [36, 39, 54], whereas the morphology [55] and circuit connectivity of infragranular L5 pyramids [38] give them access to internally generated whisking envelope signals [40]. Neural tuning for the azimuthal angle of touched objects has been hypothesized to arise from combining whisking phase and envelope signals with touch at an unspecified location [34]. Our data suggest that object-location tuning emerges from integration of touch and whisking signals within or prior to L5 in S1.\n\nHow is the transition from self-motion to object-location representation accomplished? At least three mechanisms could play a role. First, touch-induced follicle stresses differ from those during free-whisking [12], so distinct patterns of mechanosensory transduction [13] likely underlie at least part of output shift. Second, touch and whisking are encoded by largely distinct populations in superficial layers [56], which project to L5B [44, 57]. Thus, touch recruits a new set of interlaminar S1 projections that influence L5 responses. Third, touch could enhance integration of distant inputs on L5 dendrites [43] by transient changes in dendritic conductances [58]. M1 input is strongest in electrically distant tuft dendrites of L5 neurons [38]. Thus, touch could transiently increase the influence of efference copy from M1 on L5 activity, further contributing to the distinct representation. Determining the extent to which each of these possible mechanisms contribute to object-location tuning in L5 of S1 may reveal more general principles for how the transformation from sensation to perception is accomplished by cortical circuits.\n\nMaterials and methods\n\nLead contact and materials availability\n\nFurther information and requests for resources and reagents should be directed to and will be fulfilled by the lead contact, Samuel Andrew Hires (shires@usc.edu).\n\nEthics statement\n\nAll procedures were approved under USC IACUC protocols 20169 and 20788 in accordance with United States national guidelines issued by Office of Laboratory Animal Welfare of the National Institute of Health.\n\nExperimental model and subject details\n\nSixteen VGAT-ChR2-EYFP mice (JAX B6.Cg-Tg), both male and female, of at least 3 mo of age were used for the following experiments. A complete description of the head-plate procedure has been documented in previous work [59]. Postoperatively, mice were housed with littermates or singly housed if fighting occurred. Mice were provided food ad libitum and water restricted to 1 mL per day for 1 wk before training and recording. A daily health and weight assessment was completed to ensure mice were healthy.\n\nMethod details\n\nObject-localization task\n\nMice were trained in a whisker-based go/no-go object-localization task. Using a single whisker (C2), water-restricted mice were motivated to whisk and identify the location of a smooth vertical pole (0.6-mm diameter) 7–12 mm lateral from the whisker pad. The pole moved along the anteroposterior axis across 10 mm and was positioned using stepper linear actuators with 99-nm resolution, 25-μm accuracy, and &lt;5-μm repeatability (Zaber NA11B30-T4). To avoid potential ultrasonic cues associated with stepper motor movement, the pole was jittered 0–127 microsteps (0–25 μm) on each trial. A pneumatic linear slider (Festo) was used to raise the pole vertically into touch reach for each trial. The Festo also provided a sound cue on pole presentation onset.\n\nSpecific pole locations rewarded mice with water (4–8 μL), punished mice with a time-out (2 s), or had no effect based on the mouse’s decision to lick or withhold licking. In a go/no-go paradigm, four trial outcomes exist. In a minority of sessions in which the animals were trained, the close posterior 5 mm of pole locations (go) were rewarded with water rewards upon licking (hit) or had no effect if mice withheld licking (miss). The far anterior 5 mm of pole locations (no-go) were punished with time-out (false alarm) or had no effect if mice withheld licking (correct rejection). For the remaining sessions, rewards and punishment were given regardless of the pole location—go trials and no-go trials had overlapping pole locations.\n\nBehavior, videography, and electrophysiology\n\nAnimal behavior, videography, and electrophysiology were synchronized and captured during task performance using EPHUS (https://www.janelia.org/open-science/ephus). A single computer running BControl (MATLAB 2007b) was used to initiate each trial of the object-localization task and synchronize video and electrophysiology recordings via a second computer running EPHUS. Trial onset triggered high-speed video capture of whisker motion (1,000 fps) and electrophysiology recording of single-unit activity (MultiClamp 700b).\n\nWhisker motion was captured from an overhead view and spanned 4 s, spanning the period prior to pole onset to response window. Video frames were acquired using Basler acA200-340kmNIR camera and Edmund Optics 0.18X 1⁄2” GoldTL Telecentric Lens (Model # 52–258) under 940-nm illumination on Streampix 6 software. Whisker shape and position were traced and tracked using Janelia Farm’s Whisker Tracker (https://www.janelia.org/open-science/whisk-whisker-tracking). A mask was traced around the edge of the fur to reduce tracking noise. Whisker angle is quantified at the intersection between the mask and the whisker. The whisker midpoint, instantaneous phase, and amplitude were decomposed from the bandpass- and zero phase–filtered (6–60 Hz, Butterworth) whisker-angle time series using the Hilbert Transform (MATLAB 2018b: hilbert). Whisking amplitude and phase are defined as the magnitude and phase angle (radians) of the Hilbert Transform of the whisker-angle time series, respectively. A phase value of 0 is the most protracted location of the whisk cycle, π and −π are the most retracted position in that cycle, and the sign of +/− define retraction or protraction whisking directions. Whisking midpoint is the filtered (6–60 Hz) difference between whisker-angle time series and bandpass-filtered signal. Whisker curvature is the amount of bending of the whisker measured 3–5 mm lateral from the whisker mask.\n\nThe precise millisecond of touch was determined through custom MATLAB software using distance to pole and change in whisker curvature. This was followed with manual curation of images of uncertain whisker and pole intersections.\n\nIn vivo loose-seal juxtacellular recordings\n\nAll animals used in this study were adult male or female transgenic mice (VGAT-ChR2-EYFP) expressing channelrhodopsin in inhibitory units. Following head-plate surgery, mice were trimmed to one whisker (C2), and intrinsic signal imaging was used to target the barrel column associated. A single whisker was maintained throughout training and recording. Prior to recording, animals were anesthetized (2% isofluorane) and a small craniotomy (200–300 μm) was made above the barrel column associated with the C2 whisker. On the first day of recording, animals were allowed to recover for 1 h before recording. Recordings were repeated for 4.8 ± 1.5 sessions (mean ± SD) per animal.\n\nTo sample single-unit spiking activity in a manner unbiased by firing rate, blind juxtacellular loose-seal patch recordings were targeted to L5 (600–950 μm from pia [44]) neurons using patch pipettes (Warner Instruments; 5–8 MΩ) filled with 0.9% saline (Growcells). Electrical recordings (n = 149 neurons) were acquired and amplified using MultiClamp 700b and Headstage CV-7B. The pipette axis was aligned parallel to the C2 barrel column at 35°. To perform an unbiased sampling of L5, we recorded from any isolated unit. An isolated unit was identified by an increase in resistance to 15–20 MΩ. Once a unit was isolated, 10 trials of the behavioral task was run to test for spikes during performance. If spikes were observed, an isolated unit was maintained for at least 100 trials (137 ± 57; mean ± SD). Upon recording completion, 10 trials of a 10-Hz pulse of blue light (473 nm, 10 pulses for 20 ms each at 15–20 milliwatts, beam width 200-μm diameter at skull, UltraLasers Model CST-L-473 nm– 50—OEM) focused onto the recording site from overhead was used to test whether the recorded unit was an interneuron. Short latency spiking (or inhibition) to the light pulse indicated if the neuron was putative inhibitory (or excitatory) (S1C Fig). Fourteen units were putative inhibitory and excluded from analysis. The spike waveforms of these units clustered (S1F Fig) but were not cleanly separable from the excitatory population based on waveform alone. This is consistent with the diversity of inhibitory cell types in barrel cortex and with possible cell-type misidentification due to inhibitory network effects. On the other hand, if an isolated unit did not spike after 10 trials, a current pulse (100 μs, 20 nanoamps) was injected to check if a unit was attached. If a burst of spikes was observed, we deemed that neuron a silent cell.\n\nHistology\n\nDiI (ThermoFisher D282) was coated onto a patch pipette and inserted into the recording location on the final day of recording to identify the location of recordings. DiI-coated pipettes were inserted 1,000 μm deep into the recording location and left there for 5 min to ensure proper coating of the recording location. Two hours post dye, animals were deeply anesthetized with ketamine (110 mg/kg) and xylazine (10 mg/kg) cocktail before perfusion with 0.1 M sodium phosphate buffer, followed by 4% paraformaldehyde (PFA, in 0.1 M sodium phosphate buffer). The fixed brain was then flattened along the axis perpendicular to the barrel column.\n\nThe flattened brain was immersed in 4% PFA for 1 h post perfusion and transferred to 20% sucrose solution for 1 d and then 30% sucrose for 1 d. Slices (100 μm) were cut tangentially and cytochrome oxidase staining was performed to reveal the barrel columns. Fluorescence imaging was done to recover the location of the DiI track. Recording location was determined by overlapping fluorescent track on top of bright-field imaging of barrel columns.\n\nQuantification and statistical analysis\n\nDefining touch-response window\n\nA smoothed (Bayesian adaptive regression splines [BARS]; [60]) response −50 ms to 50 ms around touch was used to evaluate the touch-response window. The touch-response window is defined as any time point from 5 to 50 ms post touch in the smoothed response that exceeded baseline (−50 to 0 ms pre-touch) ± the 95% confidence interval. Two criteria were imposed to ensure an accurate response window was captured: (1) the mean firing rate of the touch response had to be &gt;2 Hz; (2) the touch-response window had to be &gt;4 ms. A touch neuron is defined as any neuron that had a touch-response window.\n\nTuning curves\n\nA tuning curve is the response (firing rate) as a function of a stimulus (e.g., whisker position). For a single neuron, 5% of sampled touches or 5% of total whisking time points were used to define a point along the touch- or whisking-tuning curve. This method ensured 20 equally sampled bins consisting of stimulus (e.g., whisker position) and response (firing rates) values. For touch tuning, the response is defined as the firing rate within the touch-response window as defined above. For whisking tuning, the same response window as touch was used. If a neuron was not tuned to touch, the median touch-response window across all neurons was used to evaluate whisking tuning. The median touch-response window is 10–28 ms post touch. The stimulus value is defined as the median of the stimulus in each sampled bin. Response values are defined as the mean of the responses in each sampled bin. Tuning curves were generated by smoothing using BARS on the stimulus and response values. Neurons that had mean whisking responses less than 2 Hz were not evaluated.\n\nTo define whether a neuron was tuned to a specific location, we used a two-step process. We first performed a one-way ANOVA at alpha level of 0.01 to identify if any position’s firing rate at touch or during free-whisking was significantly different from another. If a neuron passed this first test, we moved onto the second step of the evaluation. In the second step, we shuffled touch/whisking responses 1,000 times and evaluated F-values from a one-way ANOVA. If the observed F-value was above the 95th percentile of the shuffled population distribution of F-values, we deemed the neuron as tuned. This second evaluation further ensures that the tuning we observed was not due to noise in neural responses. A neuron was considered location-tuned if it passed both tests.\n\nTuning preference is the location of the peak response of the tuning curve. To define the width of the tuning, a multiple comparison test using a Tukey-Kramer–type critical value was used to identify the first bins in both directions that were significantly different from the peak value. If no bins were significant, no modulation width was defined. Max and min responses were calculated from BARS-fitted tuning curves.\n\nIn computing tuning curves using whisker angle at touch instead of object location, we find that two more units qualify as tuned (S5B and S5C Fig). The two units exhibit a nonlinear second-order polynomial relationship between whisker angle and pole location. This second-order polynomial fit leads to nonlinear increases in whisker angles for incremental gains in pole location, causing those two units to have tuning to far locations not seen when observing pole locations.\n\nModulation\n\nThe absolute modulation depth and modulation depth for each tuning curve are calculated as:\n\nNeural decoding\n\nWe used multinomial logistic regression to decode pole location implemented using glmnet [61]. Only touch units that sampled at least 80% of the pole location range were used for decoding. Each unit had a tuning curve that was interpolated to 40 bins to estimate location to 0.25-mm resolution. At each bin, 50 samples were drawn from a Poisson pdf with a λ as the mean of each interpolated bin. We justified drawing from a Poisson pdf because we found that at touch the number of spikes generated in the touch-response window followed a Fano factor of 0.94 ± 0.22 (mean ± SD, S3E Fig). For the design matrix, each row is a location bin, each column a single neuron, and each entry a sampled neural response for the associated neuron.\n\nThe decoder was run for 10 iterations. During each iteration, a random 70% of trials were allocated for training and the remaining 30% for test. Lasso regularization (alpha parameter 0.95) was used to reduce overfitting. To identify the number of units required, we sampled varying numbers of neurons with replacement from the units used to train the original model 500 times. The indices of the selected neurons were used to create a new population design matrix and matrix of learned coefficients from the original design matrix and learned coefficients. The prediction probabilities of location were computed by the below:\n\nwhere hθ(x) is the hypothesis function, θT are the learned coefficients, x is the input design matrix, and g(z) is the normal function of logistic regression used to calculate prediction probabilities.\n\nThe predicted location was chosen as the location with the highest probability. Model evaluation of accuracy and resolution was performed on the test set. Model accuracy is defined as the total number of correct predictions divided by the total number of predictions. A confusion matrix made from true and predicted locations was normalized across the total number of given true cases and used to define the decoding resolution and neurometric curves. Decoding resolution is defined as the total number of predictions within n bins of the diagonal, where each bin was 0.25 mm. Neurometric curves, defined here as the choice to lick given neural activity, is defined as the sum of predictions along true values for the go predictions (left half of the confusion matrix). Simulated neurometric curve performance for licks were defined as any lick probability that exceed 50%.\n\nSupporting information"
}